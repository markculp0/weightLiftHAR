---
title: "Weight Lifting, Human Activity Recognition (HAR)"
author: "Mark Culp"
date: "May 29, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
```
### Executive Summary

The goal of this project was to predict the manner in which six individuals performed various exercises based on accelerometer readings taken during their exercises.  The authors of the study developed a five-tier classification system which ranked the quality of the participants' weight lifting exercises.  

The Random Forest algorithm was used to predict the ranking of 20 different test cases based on accelerometer readings taken from the belt, forearm, arm, and dumbell of the six study participants.  Testing conducted on the validation set used in this study returned a 99% to 100% estimated, out-of-sample accuracy for our model.  


### Load Test and Training Set Data

```{r cache=TRUE}

## Load Training Set Data
training <- read.csv("../data/pml-training.csv")

## Load Testing Set Data
testing <- read.csv("../data/pml-testing.csv")


```

### Exploratory Analysis

```{r}

## Explore set dimensions
dim(training)
dim(testing )

# Identify set column name differences
trainCol <- names(training)
testCol <- names(testing)
setdiff(trainCol, testCol)
setdiff(testCol, trainCol)

# Assess numbers in each class
table(training$classe)

# Examine grouping of test data
testing$problem_id

## Get 6 user names
unique(sort(training$user_name))

```

### Clean and Partition Data

```{r warning=FALSE, message=FALSE}

# Create function to assess number of NAs in data sets
na_count <-function (x) sapply(x, function(y) sum(is.na(y)))

# Identify columns that do no have primarily NA values
boolNotNAs <- na_count(training) < 19000

# Subset test and training sets to filter out 
# primarily NA columns 
train2 <- training[,boolNotNAs]
test2 <- testing[,boolNotNAs]

# Create function to assess number of blank
# values in factor columns
empty_count <-function (x) sapply(x, function(y) sum(y == ""))

# Identify columns that do not have primarily
# blank factor contents
boolNotEmpty <- empty_count(train2) < 19000

# Subset test and training sets to filter out 
# columns with primarily blank factor contents
train3 <- train2[,boolNotEmpty]
test3 <- test2[,boolNotEmpty]

# Filter out index, timeseries, and windowing columns
train4 <- train3[,-c(1,3:7)] 
test4 <- test3[,-c(1,3:7)] 
rm(test3,train3)

# Load caret for data partitioning
library(caret)

# Create validation test set
inTrain <- createDataPartition(train4$classe, p=0.7, list = F)
train4 <- train4[inTrain,]
valid4 <- train4[-inTrain,]

```

Our initial test and training data sets each contain 160 variables.  We are able to reduce the number of variables of concern to 93 by filtering out continuous training set variables with over 19,000 (97%) NA values.  We are able to further reduce the number of variables of concern to 60 by filtering out factor variables with over 19,000 (97%) empty string values.  

We filter out 6 more variables by eliminating the index, timeseries, and windowing columns.  We do this in order to focus on the accelerometer measurements rather than the manner in which these measurements were collected.  

### Train Model and Validate Predictions

```{r message=F, warning=FALSE, cache=TRUE}

# Load caret, randomForest
library(caret)
# library(randomForest)

ctrl <- trainControl(method = "oob")

set.seed(1235)

# Train model using Random Forest
modFit <- train(classe ~ ., data = train4, method = "rf", prox = T, importance = T, trControl = ctrl)

# Predict outcomes on the validation set 
predValid <- predict(modFit, newdata = valid4)

# Assess prediction accuracy
confusionMatrix(predValid, valid4$classe)

# Calculate the error rate of preditions
sum(predValid != valid4$classe)/length(predValid)

```
The random forest algorithm builds multiple classification trees it uses to select the correct prediction for a given set of input vectors.  The trees "vote" on the final classification for each outcome, and the classification receiving the most votes wins.  According to Leo Breiman and Adele Cutler, the authors of the algorithm, random forests are unexcelled in accuracy among the current algorithms.  It was selected for this test because the algorithm works efficiently on large databases, and can handle thousands of input variables.  

According to Breiman and Cutler, there is no need for cross-validation or a separate test set to get an unbiased estimate of the test set error.  An out-of-bag (oob) error estimate is constructed at run time using about one-third of the test cases which are omitted from the bootstrap sample.  The authors indicate these estimates to be unbiased in many tests.  

Our own confusion matrix test of the HAR validation set resulted in a 99% to 100% accuracy rate in predictions on the five Class categories used to assess exercise performance.  As reflected by our misclassification calculation above, this results in a negligible out-of-sample error rate.   


### Predictions on Test Set and Findings

```{r}

library(caret)

# Predict outcomes on the validation set 
predTest <- predict(modFit, newdata = test4)

# Predictions for the 20 test cases were as
# follows:
predTest


```

The random forest model resulted in the above listed 20 predictions for the test set provided for this exercise.  We estimate an out-of-sample error rate of less than 1% using the Random Forest algorithm.    

References: 

Random Forests, Leo Breiman and Adele Cutler, Random Forests(tm) is a trademark of Leo Breiman and Adele Cutler and is licensed exclusively to Salford Systems for the commercial release of their software.

Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.

